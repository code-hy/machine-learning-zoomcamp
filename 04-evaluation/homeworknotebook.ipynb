import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, KFold
from sklearn.feature_extraction import DictVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score
import warnings
warnings.filterwarnings('ignore')

# Load data
url = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'
df = pd.read_csv(url)

# Handle missing values
categorical = df.select_dtypes(include=['object']).columns
numerical = df.select_dtypes(include=['int64', 'float64']).columns.drop('converted')

df[categorical] = df[categorical].fillna('NA')
df[numerical] = df[numerical].fillna(0.0)

# Split  60% train, 20% val, 20% test
y = df['converted']
X = df.drop('converted', axis=1)

X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1, stratify=y_temp)

# Question 1: ROC AUC for numerical features
numerical_vars = ['lead_score', 'number_of_courses_viewed', 'interaction_count', 'annual_income']
auc_scores = {}

for col in numerical_vars:
    score = roc_auc_score(y_train, X_train[col])
    if score < 0.5:
        score = roc_auc_score(y_train, -X_train[col])
    auc_scores[col] = score

best_feature = max(auc_scores, key=auc_scores.get)
print("Question 1 - Best feature:", best_feature, "AUC:", round(auc_scores[best_feature], 4))

# Prepare data for modeling
train_dicts = X_train.to_dict(orient='records')
val_dicts = X_val.to_dict(orient='records')

dv = DictVectorizer(sparse=False)
X_train_encoded = dv.fit_transform(train_dicts)
X_val_encoded = dv.transform(val_dicts)

# Question 2: Train logistic regression and compute AUC on validation
model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)
model.fit(X_train_encoded, y_train)
y_pred_val = model.predict_proba(X_val_encoded)[:, 1]
auc_val = roc_auc_score(y_val, y_pred_val)
print("Question 2 - Validation AUC:", round(auc_val, 3))

# Question 3: Precision-Recall intersection
precisions, recalls, thresholds = precision_recall_curve(y_val, y_pred_val)
# Find closest point where precision â‰ˆ recall
diff = np.abs(precisions - recalls)
idx = np.argmin(diff)
threshold_intersect = thresholds[idx] if idx < len(thresholds) else 1.0
print("Question 3 - Threshold where P=R:", round(threshold_intersect, 3))

# Question 4: Max F1 threshold
f1_scores = []
thr_range = np.arange(0.0, 1.01, 0.01)
for t in thr_range:
    y_pred_t = (y_pred_val >= t).astype(int)
    f1 = f1_score(y_val, y_pred_t)
    f1_scores.append(f1)

best_idx = np.argmax(f1_scores)
best_threshold_f1 = thr_range[best_idx]
print("Question 4 - Threshold with max F1:", round(best_threshold_f1, 2))

# Question 5: 5-Fold CV on full train+val
from sklearn.model_selection import KFold

df_full_train = pd.concat([X_train, X_val])
y_full_train = pd.concat([y_train, y_val])

kfold = KFold(n_splits=5, shuffle=True, random_state=1)
scores = []

for train_idx, val_idx in kfold.split(df_full_train):
    df_train_fold = df_full_train.iloc[train_idx]
    df_val_fold = df_full_train.iloc[val_idx]
    y_train_fold = y_full_train.iloc[train_idx]
    y_val_fold = y_full_train.iloc[val_idx]

    train_dicts_fold = df_train_fold.to_dict(orient='records')
    val_dicts_fold = df_val_fold.to_dict(orient='records')

    dv_fold = DictVectorizer(sparse=False)
    X_train_f = dv_fold.fit_transform(train_dicts_fold)
    X_val_f = dv_fold.transform(val_dicts_fold)

    model_fold = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)
    model_fold.fit(X_train_f, y_train_fold)
    y_pred_f = model_fold.predict_proba(X_val_f)[:, 1]
    auc_f = roc_auc_score(y_val_fold, y_pred_f)
    scores.append(auc_f)

std_score = np.std(scores)
print("Question 5 - Std of CV scores:", round(std_score, 4))

# Question 6: Hyperparameter tuning for C
C_values = [0.000001, 0.001, 1]
results = []

for C in C_values:
    scores_c = []
    for train_idx, val_idx in kfold.split(df_full_train):
        df_train_fold = df_full_train.iloc[train_idx]
        df_val_fold = df_full_train.iloc[val_idx]
        y_train_fold = y_full_train.iloc[train_idx]
        y_val_fold = y_full_train.iloc[val_idx]

        train_dicts_fold = df_train_fold.to_dict(orient='records')
        val_dicts_fold = df_val_fold.to_dict(orient='records')

        dv_fold = DictVectorizer(sparse=False)
        X_train_f = dv_fold.fit_transform(train_dicts_fold)
        X_val_f = dv_fold.transform(val_dicts_fold)

        model_fold = LogisticRegression(solver='liblinear', C=C, max_iter=1000)
        model_fold.fit(X_train_f, y_train_fold)
        y_pred_f = model_fold.predict_proba(X_val_f)[:, 1]
        auc_f = roc_auc_score(y_val_fold, y_pred_f)
        scores_c.append(auc_f)
    
    mean_score = np.mean(scores_c)
    std_score_c = np.std(scores_c)
    results.append((C, mean_score, std_score_c))

# Select best C: highest mean, then lowest std, then smallest C
best_result = max(results, key=lambda x: (x[1], -x[2], -x[0]))
print("Question 6 - Best C:", best_result[0])
